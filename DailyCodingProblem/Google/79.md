# Google ![Difficulty](https://img.shields.io/badge/-HARD-red)
	
Design a system to crawl and copy all of Wikipedia using a distributed network of machines.
	
More specifically, suppose your server has access to a set of client machines. Your client machines can execute code you have written to access Wikipedia pages, download and parse their data, and write the results to a database.
	
Some questions you may want to consider as part of your solution are:
	






	
